{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce93214",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2a1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_OUTPUT_DIR = \"..\\dataset_processed\" # Base output directory for processed images and masks\n",
    "IMAGES_OUT_DIR = Path(BASE_OUTPUT_DIR, \"images\")\n",
    "MASKS_OUT_DIR = Path(BASE_OUTPUT_DIR, \"masks\")\n",
    "LAST_MODIFIED_FILE = Path(BASE_OUTPUT_DIR, \"lastmodified.txt\")\n",
    "\n",
    "# User-specified path to the root of local image folders\n",
    "LOCAL_IMAGE_ROOT_DIR = r\"..\\dataset\\images\" #Needs to be changed by user\n",
    "\n",
    "# Default downscaling interpolation method\n",
    "DOWNSCALE_INTERPOLATION = cv2.INTER_AREA\n",
    "\n",
    "# Grayscale mapping for masks\n",
    "LABEL_TO_VALUE = {\n",
    "    \"upright\": 0,\n",
    "    \"fallen\": 1,\n",
    "    \"other\": 2,\n",
    "    \"unlabeled\": 3, # Used for checking, but chips with \"unlabeled\" are skipped\n",
    "    \"incomplete\": 4 # Used for checking, images with \"incomplete\" are skipped\n",
    "}\n",
    "NO_LABEL_TEMP_VALUE = 255 # Temporary value for pixels not yet labeled in a chip mask\n",
    "\n",
    "# Chip settings\n",
    "CHIP_SIZE = 512\n",
    "STRIDE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb28ae",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bc925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_cvat_xml(xml_file):\n",
    "    \"\"\"Parses the CVAT XML file.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML file {xml_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "    project_meta = root.find('meta')\n",
    "    project_updated_str = project_meta.find('project/updated').text if project_meta.find('project/updated') is not None else None\n",
    "    \n",
    "    tasks_data = {}\n",
    "    raw_tasks = project_meta.findall('.//task')\n",
    "    for task_elem in raw_tasks:\n",
    "        task_id = task_elem.find('id').text\n",
    "        task_name = task_elem.find('name').text\n",
    "        task_updated_str = task_elem.find('updated').text\n",
    "        try:\n",
    "            task_updated_dt = datetime.fromisoformat(task_updated_str)\n",
    "        except ValueError:\n",
    "            # Try to parse if it has milliseconds with 6 digits and a Z\n",
    "            if '.' in task_updated_str and task_updated_str.endswith('Z'):\n",
    "                 task_updated_str = task_updated_str.split('.')[0] + '.' + task_updated_str.split('.')[1][:6] + '+00:00'\n",
    "                 task_updated_dt = datetime.fromisoformat(task_updated_str)\n",
    "            elif '.' in task_updated_str and task_updated_str.endswith('+00:00'): # Python < 3.11 needs Z converted\n",
    "                task_updated_dt = datetime.fromisoformat(task_updated_str.replace('Z', '+00:00'))\n",
    "\n",
    "            else: # Fallback if parsing still fails, or provide a default\n",
    "                print(f\"Warning: Could not parse timestamp '{task_updated_str}' for task {task_id}. Using current time as fallback.\")\n",
    "                task_updated_dt = datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "        tasks_data[task_id] = {\n",
    "            \"name\": task_name,\n",
    "            \"updated\": task_updated_dt,\n",
    "            \"images\": []\n",
    "        }\n",
    "\n",
    "    images_annotations = {}\n",
    "    for image_elem in root.findall(\".//image\"):\n",
    "        image_id = image_elem.get(\"id\")\n",
    "        image_name = image_elem.get(\"name\")\n",
    "        task_id = image_elem.get(\"task_id\")\n",
    "        width = int(image_elem.get(\"width\"))\n",
    "        height = int(image_elem.get(\"height\"))\n",
    "\n",
    "        annotations = []\n",
    "        for poly_elem in image_elem.findall(\"polygon\"):\n",
    "            label = poly_elem.get(\"label\")\n",
    "            points_str = poly_elem.get(\"points\")\n",
    "            points = [list(map(float, p.split(','))) for p in points_str.split(';')]\n",
    "            annotations.append({\"type\": \"polygon\", \"label\": label, \"points\": points, \"source_elem\": poly_elem})\n",
    "\n",
    "        for box_elem in image_elem.findall(\"box\"):\n",
    "            label = box_elem.get(\"label\")\n",
    "            xtl = float(box_elem.get(\"xtl\"))\n",
    "            ytl = float(box_elem.get(\"ytl\"))\n",
    "            xbr = float(box_elem.get(\"xbr\"))\n",
    "            ybr = float(box_elem.get(\"ybr\"))\n",
    "            points = [(xtl, ytl), (xbr, ytl), (xbr, ybr), (xtl, ybr)]\n",
    "            annotations.append({\"type\": \"box\", \"label\": label, \"points\": points, \"source_elem\": box_elem})\n",
    "        \n",
    "        if task_id in tasks_data:\n",
    "            tasks_data[task_id][\"images\"].append({\n",
    "                \"id\": image_id,\n",
    "                \"name\": image_name,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"annotations\": annotations\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Image {image_name} references task_id {task_id} which was not found in project metadata.\")\n",
    "\n",
    "    # Filter out tasks that have no images associated directly in the parsed structure\n",
    "    # (though typically all images should link to a task)\n",
    "    # Also, combine task info with image annotations\n",
    "    processed_tasks = {}\n",
    "    for task_id, task_info in tasks_data.items():\n",
    "        if task_info[\"images\"]:\n",
    "             processed_tasks[task_id] = task_info\n",
    "\n",
    "\n",
    "    return processed_tasks\n",
    "\n",
    "\n",
    "def read_server_paths(csv_path):\n",
    "    \"\"\"Reads server paths from the CSV file.\"\"\"\n",
    "    paths = {}\n",
    "    try:\n",
    "        with open(csv_path, mode='r', newline='') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            next(reader)  # Skip header\n",
    "            for row in reader:\n",
    "                if row: # ensure row is not empty\n",
    "                    location_name, server_folder_path, *_ = row # handles rows with more than 2 columns\n",
    "                    paths[location_name.strip()] = server_folder_path.strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Server paths CSV '{csv_path}' not found. Image download will not be possible.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading server paths CSV '{csv_path}': {e}\")\n",
    "    return paths \n",
    "\n",
    "def get_last_modified_timestamp():\n",
    "    \"\"\"Reads the last modified timestamp from the file.\"\"\"\n",
    "    if LAST_MODIFIED_FILE.exists():\n",
    "        try:\n",
    "            return datetime.fromisoformat(LAST_MODIFIED_FILE.read_text().strip())\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not parse timestamp from {LAST_MODIFIED_FILE}. Processing all images.\")\n",
    "            return datetime.min.replace(tzinfo=timezone.utc) # Process all if timestamp is invalid\n",
    "    return datetime.min.replace(tzinfo=timezone.utc) # Process all if file doesn't exist\n",
    "\n",
    "def set_last_modified_timestamp():\n",
    "    \"\"\"Writes the current timestamp to the last modified file.\"\"\"\n",
    "    if not BASE_OUTPUT_DIR.exists():\n",
    "        os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    LAST_MODIFIED_FILE.write_text(datetime.now(timezone.utc).isoformat())\n",
    "\n",
    "def scale_annotations(annotations, scale_factor):\n",
    "    \"\"\"Scales annotation coordinates.\"\"\"\n",
    "    scaled_annotations = []\n",
    "    for ann in annotations:\n",
    "        scaled_points = [[p[0] * scale_factor, p[1] * scale_factor] for p in ann[\"points\"]]\n",
    "        scaled_annotations.append({**ann, \"points\": scaled_points})\n",
    "    return scaled_annotations\n",
    "\n",
    "def ensure_dir(path): \n",
    "    \"\"\"Ensures a directory exists.\"\"\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Updated get_image_full_path function\n",
    "def get_image_full_path(image_name, task_name, server_paths_csv_data):\n",
    "    \"\"\"Tries to find the image locally, then on the server.\n",
    "    Downloads the image locally if found on the server.\n",
    "    Returns the local path if found, None otherwise.\n",
    "    \"\"\"\n",
    "    local_path = Path(LOCAL_IMAGE_ROOT_DIR, task_name, image_name)\n",
    "    if local_path.exists():\n",
    "        print(f\"Found image locally: {local_path}\")\n",
    "        return str(local_path)\n",
    "    \n",
    "    print(f\"Image not found locally: {local_path}. Attempting server lookup...\")\n",
    "    if task_name in server_paths_csv_data:\n",
    "        server_folder_path = server_paths_csv_data[task_name]\n",
    "        # Check if server_folder_path is a UNC path or local-like\n",
    "        if server_folder_path.startswith(\"\\\\\\\\\") or Path(server_folder_path).drive:\n",
    "            potential_server_path = Path(server_folder_path, image_name)\n",
    "            if potential_server_path.exists():\n",
    "                print(f\"Found image on server: {potential_server_path}\")\n",
    "                # Ensure the local folder exists before downloading\n",
    "                if not local_path.parent.exists():\n",
    "                    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                try:\n",
    "                    # \"Download\" the image by copying it from the server to the local destination\n",
    "                    shutil.copy2(potential_server_path, local_path)\n",
    "                    print(f\"Image downloaded to {local_path}\")\n",
    "                    return str(local_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading image from server: {e}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Image {image_name} not found at server path: {potential_server_path}\")\n",
    "        else:\n",
    "            print(f\"Server path for {task_name} ('{server_folder_path}') is not a recognized file system path.\")\n",
    "    else:\n",
    "        print(f\"No server path entry found for location: {task_name} in CSV.\")\n",
    "    \n",
    "    print(f\"Failed to find image '{image_name}' for task '{task_name}' both locally and on server.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def polygon_intersects_bbox(poly_points, bbox_min_x, bbox_min_y, bbox_max_x, bbox_max_y):\n",
    "    \"\"\"\n",
    "    Basic check if a polygon's bounding box intersects with the given bounding box.\n",
    "    This is an approximation; for precise checks, more complex geometry operations are needed.\n",
    "    \"\"\"\n",
    "    if not poly_points:\n",
    "        return False\n",
    "    \n",
    "    poly_min_x = min(p[0] for p in poly_points)\n",
    "    poly_max_x = max(p[0] for p in poly_points)\n",
    "    poly_min_y = min(p[1] for p in poly_points)\n",
    "    poly_max_y = max(p[1] for p in poly_points)\n",
    "\n",
    "    # Check for non-overlap\n",
    "    if poly_max_x < bbox_min_x or poly_min_x > bbox_max_x:\n",
    "        return False\n",
    "    if poly_max_y < bbox_min_y or poly_min_y > bbox_max_y:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "def process_images(cvat_xml_path, server_paths_csv_path):\n",
    "    \"\"\"Main function to process images and generate dataset.\"\"\"\n",
    "    \n",
    "    print(f\"Starting dataset generation process at {datetime.now()}\")\n",
    "    print(f\"CVAT XML: {cvat_xml_path}\")\n",
    "    print(f\"Server Paths CSV: {server_paths_csv_path}\")\n",
    "    print(f\"Local Image Root: {LOCAL_IMAGE_ROOT_DIR}\")\n",
    "    print(f\"Output Directory: {BASE_OUTPUT_DIR}\")\n",
    "\n",
    "    tasks = parse_cvat_xml(cvat_xml_path)\n",
    "    if not tasks:\n",
    "        print(\"No tasks found or error parsing XML. Exiting.\")\n",
    "        return\n",
    "\n",
    "    server_paths_data = read_server_paths(server_paths_csv_path)\n",
    "    last_processed_time = get_last_modified_timestamp()\n",
    "    print(f\"Last processed time: {last_processed_time}\")\n",
    "    \n",
    "    ensure_dir(IMAGES_OUT_DIR)\n",
    "    ensure_dir(MASKS_OUT_DIR)\n",
    "\n",
    "    images_processed_count = 0\n",
    "    chips_generated_count = 0\n",
    "\n",
    "    for task_id, task_data in tasks.items():\n",
    "        task_name = task_data[\"name\"]\n",
    "        task_updated_time = task_data[\"updated\"]\n",
    "\n",
    "        # Ensure both datetimes are timezone-aware (UTC)\n",
    "        if task_updated_time.tzinfo is None:\n",
    "            task_updated_time = task_updated_time.replace(tzinfo=timezone.utc)\n",
    "        if last_processed_time.tzinfo is None:\n",
    "            last_processed_time = last_processed_time.replace(tzinfo=timezone.utc)\n",
    "\n",
    "        if task_updated_time <= last_processed_time:\n",
    "            print(f\"Skipping task '{task_name}' (ID: {task_id}) as it has not been updated since last run ({task_updated_time}).\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing task: {task_name} (ID: {task_id}, Updated: {task_updated_time})\")\n",
    "\n",
    "        task_images_out_dir = IMAGES_OUT_DIR / task_name\n",
    "        task_masks_out_dir = MASKS_OUT_DIR / task_name\n",
    "        ensure_dir(task_images_out_dir)\n",
    "        ensure_dir(task_masks_out_dir)\n",
    "\n",
    "        for image_info in task_data[\"images\"]:\n",
    "            image_name = image_info[\"name\"]\n",
    "            print(f\"  Processing image: {image_name}\")\n",
    "\n",
    "            current_annotations = image_info[\"annotations\"]\n",
    "\n",
    "            # Error Check 1 for entire satellite image\n",
    "            all_labels_in_image = [ann[\"label\"] for ann in current_annotations]\n",
    "            has_incomplete = \"incomplete\" in all_labels_in_image\n",
    "            \n",
    "            # Check if image has annotations and if they are all \"unlabeled\"\n",
    "            if not all_labels_in_image: # No annotations at all\n",
    "                is_only_unlabeled_or_empty = True\n",
    "            else:\n",
    "                is_only_unlabeled_or_empty = all(label == \"unlabeled\" for label in all_labels_in_image)\n",
    "\n",
    "            if has_incomplete:\n",
    "                print(f\"    ERROR: Image '{image_name}' contains 'incomplete' labels. Skipping this image.\")\n",
    "                continue \n",
    "            if is_only_unlabeled_or_empty:\n",
    "                 print(f\"    ERROR: Image '{image_name}' has no valid labels or only 'unlabeled' labels. Skipping this image.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            full_image_path = get_image_full_path(image_name, task_name, server_paths_data)\n",
    "            if not full_image_path:\n",
    "                print(f\"    Could not find image '{image_name}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Read with alpha channel if present, otherwise discard it later if not needed.\n",
    "                img = cv2.imread(full_image_path, cv2.IMREAD_UNCHANGED)\n",
    "                if img is None:\n",
    "                    print(f\"    Failed to load image: {full_image_path}. Skipping.\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"    Exception loading image {full_image_path}: {e}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # If image has 4 channels (e.g., RGBA), convert to BGR for processing\n",
    "            if img.ndim == 3 and img.shape[2] == 4:\n",
    "                print(f\"    Image {image_name} has 4 channels. Converting to BGR.\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "            elif img.ndim == 2: # Grayscale image\n",
    "                print(f\"    Image {image_name} is grayscale. Converting to BGR.\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            elif img.ndim == 3 and img.shape[2] != 3:\n",
    "                 print(f\"    Image {image_name} has an unsupported number of channels: {img.shape[2]}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            h, w = img.shape[:2]\n",
    "            annotations_to_use = current_annotations\n",
    "            scale_factor = 1.0\n",
    "\n",
    "            if h > 10000 or w > 10000:\n",
    "                print(f\"    Image dimensions ({w}x{h}) > 10000. Downscaling by factor of 2.\")\n",
    "                scale_factor = 0.5\n",
    "                new_w, new_h = int(w * scale_factor), int(h * scale_factor)\n",
    "                img = cv2.resize(img, (new_w, new_h), interpolation=DOWNSCALE_INTERPOLATION)\n",
    "                # print(f\"(1) Image size tested: {w}x{h}, downscaled to {img.shape[1]}x{img.shape[0]}\")\n",
    "                # Overwrite the original image with the downscaled version\n",
    "                cv2.imwrite(full_image_path, img)\n",
    "                print(f\"    Overwrote original image with downscaled version at: {full_image_path}\")\n",
    "                annotations_to_use = scale_annotations(current_annotations, scale_factor)\n",
    "                h, w = new_h, new_w # Update dimensions\n",
    "                print(f\"    New dimensions: {w}x{h}\")\n",
    "\n",
    "\n",
    "            for y in range(0, h - CHIP_SIZE + 1, STRIDE):\n",
    "                for x in range(0, w - CHIP_SIZE + 1, STRIDE):\n",
    "                    # print(f\"img size inside loop: {img.shape[1]}x{img.shape[0]}, chip position: ({x},{y})\")\n",
    "                    img_chip = img[y:y + CHIP_SIZE, x:x + CHIP_SIZE]\n",
    "                    mask_chip = np.full((CHIP_SIZE, CHIP_SIZE), NO_LABEL_TEMP_VALUE, dtype=np.uint8)\n",
    "\n",
    "                    chip_intersecting_polygons_info = []\n",
    "                    chip_has_any_actual_label = False\n",
    "                    chip_contains_unlabeled_label_type = False\n",
    "                    \n",
    "                    # Gather polygons relevant to this chip\n",
    "                    for ann in annotations_to_use:\n",
    "                        # Basic bounding box intersection test for speed\n",
    "                        if not polygon_intersects_bbox(ann[\"points\"], x, y, x + CHIP_SIZE, y + CHIP_SIZE):\n",
    "                            continue\n",
    "\n",
    "                        if ann[\"label\"] == \"unlabeled\":\n",
    "                            chip_contains_unlabeled_label_type = True\n",
    "                            break \n",
    "                        \n",
    "                        # Convert points to be relative to the chip's origin\n",
    "                        relative_points = [[p[0] - x, p[1] - y] for p in ann[\"points\"]]\n",
    "                        \n",
    "                        if ann[\"label\"] in LABEL_TO_VALUE:\n",
    "                            chip_intersecting_polygons_info.append({\n",
    "                                \"points\": np.array(relative_points, dtype=np.int32),\n",
    "                                \"label\": ann[\"label\"],\n",
    "                                \"value\": LABEL_TO_VALUE[ann[\"label\"]]\n",
    "                            })\n",
    "                            if ann[\"label\"] != \"unlabeled\": # \"unlabeled\" itself is not an \"actual\" data label for training\n",
    "                                chip_has_any_actual_label = True\n",
    "                        # else: # Should not happen if XML is well-formed and labels are in LABEL_TO_VALUE\n",
    "                           # print(f\"    Warning: Unknown label '{ann['label']}' in image {image_name}. Skipping this annotation for chip.\")\n",
    "\n",
    "\n",
    "                    if chip_contains_unlabeled_label_type:\n",
    "                        # print(f\"    Skipping chip ({x},{y}) for {image_name}: contains 'unlabeled' type polygon.\")\n",
    "                        continue\n",
    "                    \n",
    "                    if not chip_has_any_actual_label:\n",
    "                        # print(f\"    Skipping chip ({x},{y}) for {image_name}: no actual labels found.\")\n",
    "                        continue\n",
    "\n",
    "                    # --- Special Upright Rule Check ---\n",
    "                    all_polys_in_chip_are_upright = True\n",
    "                    if not chip_intersecting_polygons_info: # Should be caught by chip_has_any_actual_label\n",
    "                        all_polys_in_chip_are_upright = False\n",
    "                    for poly_info in chip_intersecting_polygons_info:\n",
    "                        if poly_info[\"label\"] != \"upright\":\n",
    "                            all_polys_in_chip_are_upright = False\n",
    "                            break\n",
    "                    \n",
    "                    apply_all_upright_rule = False\n",
    "                    if all_polys_in_chip_are_upright and chip_intersecting_polygons_info:\n",
    "                        quadrant_hits = [False, False, False, False] # TL, TR, BL, BR\n",
    "                        q_size = CHIP_SIZE // 2\n",
    "                        \n",
    "                        for poly_info in chip_intersecting_polygons_info: # These are all \"upright\"\n",
    "                            # Create a temporary mask for this single polygon to check quadrant presence\n",
    "                            temp_poly_mask = np.zeros((CHIP_SIZE, CHIP_SIZE), dtype=np.uint8)\n",
    "                            cv2.fillPoly(temp_poly_mask, [poly_info[\"points\"]], 1)\n",
    "                            \n",
    "                            if not quadrant_hits[0] and np.any(temp_poly_mask[0:q_size, 0:q_size]):\n",
    "                                quadrant_hits[0] = True\n",
    "                            if not quadrant_hits[1] and np.any(temp_poly_mask[0:q_size, q_size:CHIP_SIZE]):\n",
    "                                quadrant_hits[1] = True\n",
    "                            if not quadrant_hits[2] and np.any(temp_poly_mask[q_size:CHIP_SIZE, 0:q_size]):\n",
    "                                quadrant_hits[2] = True\n",
    "                            if not quadrant_hits[3] and np.any(temp_poly_mask[q_size:CHIP_SIZE, q_size:CHIP_SIZE]):\n",
    "                                quadrant_hits[3] = True\n",
    "                        \n",
    "                        if all(quadrant_hits):\n",
    "                            apply_all_upright_rule = True\n",
    "\n",
    "                    if apply_all_upright_rule:\n",
    "                        mask_chip[:, :] = LABEL_TO_VALUE[\"upright\"]\n",
    "                        # print(f\"    Applied all-upright rule to chip ({x},{y}) for {image_name}.\")\n",
    "                    else:\n",
    "                        # --- Standard Mask Drawing ---\n",
    "                        # Sort polygons? (e.g. by area, or a predefined label priority if needed)\n",
    "                        # For now, draw in order of appearance.\n",
    "                        for poly_info in chip_intersecting_polygons_info:\n",
    "                             if poly_info[\"label\"] in [\"upright\", \"fallen\", \"other\"]: # Only draw trainable labels\n",
    "                                cv2.fillPoly(mask_chip, [poly_info[\"points\"]], poly_info[\"value\"])\n",
    "                        \n",
    "                        # --- Fill remaining unlabelled areas (if any) with 'upright' ---\n",
    "                        mask_chip[mask_chip == NO_LABEL_TEMP_VALUE] = LABEL_TO_VALUE[\"upright\"]\n",
    "\n",
    "                    # Save chip\n",
    "                    chip_filename_base = f\"{Path(image_name).stem}_chip_{int(x/256)}_{int(y/256)}\"\n",
    "                    img_chip_path = task_images_out_dir / f\"{chip_filename_base}.png\"\n",
    "                    mask_chip_path = task_masks_out_dir / f\"{chip_filename_base}_mask.png\"\n",
    "                    \n",
    "                    cv2.imwrite(str(img_chip_path), img_chip)\n",
    "                    cv2.imwrite(str(mask_chip_path), mask_chip)\n",
    "                    chips_generated_count += 1\n",
    "            \n",
    "            images_processed_count +=1\n",
    "\n",
    "    if images_processed_count > 0:\n",
    "        set_last_modified_timestamp()\n",
    "        print(f\"\\nFinished processing. {images_processed_count} images processed, {chips_generated_count} chips generated.\")\n",
    "        print(f\"Timestamp updated in {LAST_MODIFIED_FILE}\")\n",
    "    else:\n",
    "        print(\"\\nNo images needed processing based on timestamps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e709ec6",
   "metadata": {},
   "source": [
    "# Run the processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11572037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- User Input ---\n",
    "    # Ensure these paths are correct\n",
    "    cvat_xml_file = r\"..\\resources\\annotations.xml\"  # Path to your CVAT XML file\n",
    "    server_paths_file = r\"..\\resources\\serverpaths.csv\" # Path to your CSV file with server paths\n",
    "    \n",
    "    # Update LOCAL_IMAGE_ROOT_DIR at the top of the script if your local dataset root is different.\n",
    "\n",
    "    if not Path(cvat_xml_file).exists():\n",
    "        print(f\"Error: CVAT XML file not found at '{cvat_xml_file}'\")\n",
    "    elif not Path(server_paths_file).exists() and LOCAL_IMAGE_ROOT_DIR == \"\": # Only critical if local dir not set or for fallback\n",
    "         print(f\"Warning: Server paths CSV not found at '{server_paths_file}'. Image download/fallback may not work.\")\n",
    "         # Decide if you want to proceed or exit if CSV is mandatory for some workflows.\n",
    "         # For now, it will proceed but log warnings if images aren't found locally.\n",
    "    else:\n",
    "        process_images(cvat_xml_file, server_paths_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb0b73",
   "metadata": {},
   "source": [
    "# Display Generated Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a95b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 187\u001b[0m\n\u001b[0;32m    178\u001b[0m STRIDE_VALUE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.5\u001b[39m  \u001b[38;5;66;03m# Example: display all chips in the range\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# STRIDE_VALUE = 0.5  # Example: display every 2nd chip\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# STRIDE_VALUE = 0.25 # Example: display every 4th chip\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# STRIDE_VALUE = 0.75 # Example: will result in step 1 (1/0.75=1.33, rounds to 1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m                       \u001b[38;5;66;03m# The implemented logic ensures step_float = 2.5, effective_step = int(round(2.5)) which is 2.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m                       \u001b[38;5;66;03m# Let's test this: round(2.5) is 2. round(3.5) is 4. Correct.\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[43mdisplay_chip_grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_ROOT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOLLECTION_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFILENAME_PREFIX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_LEFT_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_LEFT_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOTTOM_RIGHT_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOTTOM_RIGHT_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchip_size_render\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHIP_DISPLAY_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTRIDE_VALUE\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the new stride parameter\u001b[39;49;00m\n\u001b[0;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m, in \u001b[0;36mdisplay_chip_grid\u001b[1;34m(dataset_root, collection_name, filename_prefix, x_start, y_start, x_end, y_end, chip_size_render, stride)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdisplay_chip_grid\u001b[39m(dataset_root, collection_name, filename_prefix,\n\u001b[0;32m     29\u001b[0m                       x_start, y_start, x_end, y_end, chip_size_render\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m     30\u001b[0m                       stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Displays a grid of image chips with their masks overlaid, with an option for striding.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m                        If 1.0/stride is not an integer, the step is rounded.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_start\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m y_end \u001b[38;5;241m<\u001b[39m y_start:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Invalid start/end coordinates. End coordinates must be greater than or equal to start.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\"Converts a hex color string to an (R, G, B) tuple.\"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# Define the color mapping for mask values\n",
    "# Greyscale class values: 0 = upright, 1 = fallen, 2 = other, 3 = unlabelled\n",
    "COLOR_MAP_HEX = {\n",
    "    0: \"#b7f2a6\",  # upright (greenish)\n",
    "    1: \"#c71933\",  # fallen (reddish)\n",
    "    2: \"#ffcc33\",  # other (yellowish)\n",
    "    3: \"#2a23bf\"   # unlabelled (bluish)\n",
    "}\n",
    "\n",
    "COLOR_MAP_RGB = {\n",
    "    value: hex_to_rgb(hex_code) for value, hex_code in COLOR_MAP_HEX.items()\n",
    "}\n",
    "\n",
    "# Alpha value for the mask overlay (0-255, where 255 is fully opaque)\n",
    "# 128 is about 50% transparency\n",
    "MASK_ALPHA = 128\n",
    "\n",
    "def display_chip_grid(dataset_root, collection_name, filename_prefix,\n",
    "                      x_start, y_start, x_end, y_end, chip_size_render=(256, 256),\n",
    "                      stride=1.0):\n",
    "    \"\"\"\n",
    "    Displays a grid of image chips with their masks overlaid, with an option for striding.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str): Path to the root directory of the dataset\n",
    "                            (e.g., \"./dataset\").\n",
    "        collection_name (str): Name of the subfolder within 'images' and 'masks'\n",
    "                               (e.g., \"centreglassville\", \"crozier\").\n",
    "        filename_prefix (str): The prefix for the image and mask files\n",
    "                               (e.g., \"centreglassville\"). This is the {filename}\n",
    "                               part in {filename}_{xidx}_{yidx}.png.\n",
    "        x_start (int): The starting x-index of the chip rectangle.\n",
    "        y_start (int): The starting y-index of the chip rectangle.\n",
    "        x_end (int): The ending x-index of the chip rectangle (inclusive).\n",
    "        y_end (int): The ending y-index of the chip rectangle (inclusive).\n",
    "        chip_size_render (tuple): Tuple (width, height) to resize images for display if needed.\n",
    "                                  Original image size is used by default for masks processing.\n",
    "        stride (float): Interval for displaying images.\n",
    "                        stride = 1.0 displays all images in the selected range.\n",
    "                        stride = 0.5 displays every 2nd image (0th, 2nd, 4th...).\n",
    "                        stride = 0.25 displays every 4th image (0th, 4th, 8th...).\n",
    "                        Values of stride > 1.0 are treated as 1.0.\n",
    "                        If 1.0/stride is not an integer, the step is rounded.\n",
    "    \"\"\"\n",
    "\n",
    "    if x_end < x_start or y_end < y_start:\n",
    "        print(\"Error: Invalid start/end coordinates. End coordinates must be greater than or equal to start.\")\n",
    "        return\n",
    "\n",
    "    # Calculate effective step from stride\n",
    "    if not isinstance(stride, (int, float)) or stride <= 0:\n",
    "        print(\"Warning: Stride must be a positive number. Defaulting to 1.0 (step 1).\")\n",
    "        effective_step = 1\n",
    "    else:\n",
    "        if stride > 1.0:  # e.g. stride = 2.0 implies step 0.5, which we treat as step 1\n",
    "            effective_step = 1\n",
    "            if stride != 1.0: # Only print warning if it was not already 1.0\n",
    "                 print(f\"Warning: Stride {stride} (>1.0) is not supported for downsampling. Using step 1 (equivalent to stride 1.0).\")\n",
    "        else:  # stride is between (0, 1.0]\n",
    "            step_float = 1.0 / stride\n",
    "            if abs(step_float - round(step_float)) < 1e-9:  # Check if step_float is very close to an integer\n",
    "                effective_step = int(round(step_float))\n",
    "            else:\n",
    "                rounded_step = int(round(step_float))\n",
    "                print(f\"Warning: For stride={stride}, the calculated step 1/{stride}={step_float:.4f} is not an integer. \"\n",
    "                      f\"Using rounded integer step: {rounded_step}.\")\n",
    "                effective_step = rounded_step\n",
    "            \n",
    "            if effective_step < 1: # Safeguard, e.g. if stride was 1.1 and slipped through\n",
    "                effective_step = 1\n",
    "    \n",
    "    y_indices_to_display = list(range(y_start, y_end + 1, effective_step))\n",
    "    x_indices_to_display = list(range(x_start, x_end + 1, effective_step))\n",
    "\n",
    "    plot_num_rows = len(y_indices_to_display)\n",
    "    plot_num_cols = len(x_indices_to_display)\n",
    "\n",
    "    if plot_num_rows == 0 or plot_num_cols == 0:\n",
    "        print(f\"No chips to display for the range (X: {x_start}-{x_end}, Y: {y_start}-{y_end}) \"\n",
    "              f\"with step {effective_step} (from stride {stride}).\")\n",
    "        return\n",
    "\n",
    "    fig, axs_obj = plt.subplots(plot_num_rows, plot_num_cols, figsize=(plot_num_cols * 3, plot_num_rows * 3), squeeze=False)\n",
    "    # squeeze=False ensures axs_obj is always a 2D array, even if plot_num_rows or plot_num_cols is 1.\n",
    "\n",
    "    for i_plot, chip_y in enumerate(y_indices_to_display):\n",
    "        for j_plot, chip_x in enumerate(x_indices_to_display):\n",
    "            ax = axs_obj[i_plot, j_plot]\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_aspect('equal') # Ensure chips are not distorted\n",
    "\n",
    "            img_filename = f\"{filename_prefix}_{chip_x}_{chip_y}.png\"\n",
    "            mask_filename = f\"{filename_prefix}_{chip_x}_{chip_y}_mask.png\"\n",
    "\n",
    "            img_path = os.path.join(dataset_root, \"images\", collection_name, img_filename)\n",
    "            mask_path = os.path.join(dataset_root, \"masks\", collection_name, mask_filename)\n",
    "            \n",
    "            try:\n",
    "                img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "                mask_pil_gray = Image.open(mask_path).convert(\"L\")\n",
    "                \n",
    "                if img_pil.size != mask_pil_gray.size:\n",
    "                    print(f\"Warning: Image {img_filename} and mask {mask_filename} have different sizes. \"\n",
    "                          f\"Image: {img_pil.size}, Mask: {mask_pil_gray.size}. Resizing mask to image size for overlay.\")\n",
    "                    mask_pil_gray = mask_pil_gray.resize(img_pil.size, Image.NEAREST)\n",
    "\n",
    "                mask_np_gray = np.array(mask_pil_gray)\n",
    "                overlay_rgba = np.zeros((mask_np_gray.shape[0], mask_np_gray.shape[1], 4), dtype=np.uint8)\n",
    "                \n",
    "                for val, rgb_color in COLOR_MAP_RGB.items():\n",
    "                    pixels_to_color = (mask_np_gray == val)\n",
    "                    overlay_rgba[pixels_to_color, 0] = rgb_color[0]\n",
    "                    overlay_rgba[pixels_to_color, 1] = rgb_color[1]\n",
    "                    overlay_rgba[pixels_to_color, 2] = rgb_color[2]\n",
    "                    overlay_rgba[pixels_to_color, 3] = MASK_ALPHA \n",
    "                \n",
    "                overlay_pil = Image.fromarray(overlay_rgba, \"RGBA\")\n",
    "\n",
    "                display_img_pil = img_pil.resize(chip_size_render, Image.Resampling.LANCZOS)\n",
    "                display_overlay_pil = overlay_pil.resize(chip_size_render, Image.Resampling.NEAREST)\n",
    "\n",
    "                ax.imshow(display_img_pil)\n",
    "                ax.imshow(display_overlay_pil)\n",
    "                ax.set_title(f\"({chip_x},{chip_y})\", fontsize=8)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                ax.set_facecolor('lightgray')\n",
    "                ax.text(0.5, 0.5, f\"No Chip\\n({chip_x},{chip_y})\", \n",
    "                        horizontalalignment='center', verticalalignment='center', \n",
    "                        fontsize=8, transform=ax.transAxes)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.spines['bottom'].set_visible(False)\n",
    "                ax.spines['left'].set_visible(False)\n",
    "            except Exception as e:\n",
    "                ax.set_facecolor('pink')\n",
    "                ax.text(0.5, 0.5, f\"Error\\n({chip_x},{chip_y})\\n{type(e).__name__}\",\n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=6, transform=ax.transAxes, color='red')\n",
    "                print(f\"Error processing chip ({chip_x},{chip_y}): {e}\")\n",
    "\n",
    "    suptitle_text = f\"Chip Grid: {collection_name} ({filename_prefix}) | X: {x_start}-{x_end}, Y: {y_start}-{y_end}\"\n",
    "    if stride != 1.0 or effective_step != 1: # Show stride/step info if not default\n",
    "        suptitle_text += f\" | Stride: {stride} (Step: {effective_step})\"\n",
    "    plt.suptitle(suptitle_text, fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.96]) # Adjust layout\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Configuration ---\n",
    "    # IMPORTANT: Replace this with the actual path to your dataset's root folder\n",
    "    DATASET_ROOT_PATH = \"../dataset_processed\" \n",
    "    \n",
    "    # COLLECTION_NAME = \"centreglassville\" \n",
    "    # FILENAME_PREFIX = \"Glassville_ortho_5cm16_chip\" \n",
    "    COLLECTION_NAME = \"crozier\"\n",
    "    FILENAME_PREFIX = \"22_Crozier_461000_5385000_chip\"\n",
    "\n",
    "    TOP_LEFT_X = 0\n",
    "    TOP_LEFT_Y = 0\n",
    "    BOTTOM_RIGHT_X = 20\n",
    "    BOTTOM_RIGHT_Y = 20 \n",
    "\n",
    "    # (Optional) Define a stride for displaying chips.\n",
    "    # 1.0 = display all. 0.5 = display every other. 0.25 = display every 4th.\n",
    "    # A stride of 2.0 would mean showing \"half\" an image, so it defaults to step 1.\n",
    "    STRIDE_VALUE = .5  # Example: display all chips in the range\n",
    "    # STRIDE_VALUE = 0.5  # Example: display every 2nd chip\n",
    "    # STRIDE_VALUE = 0.25 # Example: display every 4th chip\n",
    "    # STRIDE_VALUE = 0.75 # Example: will result in step 1 (1/0.75=1.33, rounds to 1)\n",
    "    # STRIDE_VALUE = 0.4  # Example: will result in step 2 (1/0.4=2.5, rounds to 3 or 2 depending on Python's round for .5)\n",
    "                          # My logic rounds 2.5 to 3 if using round(), but int(round(2.5)) from Python 3 is 2.\n",
    "                          # The implemented logic ensures step_float = 2.5, effective_step = int(round(2.5)) which is 2.\n",
    "                          # Let's test this: round(2.5) is 2. round(3.5) is 4. Correct.\n",
    "\n",
    "    display_chip_grid(\n",
    "        dataset_root=DATASET_ROOT_PATH,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        filename_prefix=FILENAME_PREFIX,\n",
    "        x_start=TOP_LEFT_X,\n",
    "        y_start=TOP_LEFT_Y,\n",
    "        x_end=BOTTOM_RIGHT_X,\n",
    "        y_end=BOTTOM_RIGHT_Y,\n",
    "        chip_size_render=CHIP_DISPLAY_SIZE,\n",
    "        stride=STRIDE_VALUE  # Pass the new stride parameter\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-checked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
