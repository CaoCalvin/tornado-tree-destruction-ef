{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting COCO dataset creation (No ArcPy) at 2025-05-28 11:05:26\n",
      "  TIF Folder: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\TIFFS\n",
      "  Polygon Shapefile: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\Woodstock Lake ArcGIS merged final.shp\n",
      "  Output Directory: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\n",
      "  Preparing output directory: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\n",
      "    WARNING: Output directory 'C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco' already exists.\n",
      "    It will be completely REMOVED to ensure a clean dataset generation.\n",
      "    Successfully removed existing directory: 'C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco'\n",
      "    Successfully created clean output directory: 'C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco'\n",
      "  Scaling Factor: 0.5\n",
      "  Creating necessary sub-directory structure within 'C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco'...\n",
      "    Successfully created sub-directory structure.\n",
      "      Images will be in: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\n",
      "      Annotations will be in: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\annotations\n",
      "  Loading polygons from: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\Woodstock Lake ArcGIS merged final.shp\n",
      "    Loaded 300 polygons.\n",
      "  Processing all 6 TIF files found in the folder.\n",
      "\n",
      "Processing images...\n",
      "  Attempting to process TIF: 22_Woodstock_336000_5683000.tif\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 6 polygons after clipping for 22_Woodstock_336000_5683000.tif.\n",
      "    Processing TIF: 22_Woodstock_336000_5683000.tif for dataset (Image ID: 1)\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_336000_5683000.tif\n",
      "DEBUG: For 22_Woodstock_336000_5683000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_336000_5683000.tif\n",
      "  Attempting to process TIF: 22_Woodstock_338000_5681000.tif\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 1 polygons after clipping for 22_Woodstock_338000_5681000.tif.\n",
      "    Processing TIF: 22_Woodstock_338000_5681000.tif for dataset (Image ID: 2)\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_338000_5681000.tif\n",
      "DEBUG: For 22_Woodstock_338000_5681000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_338000_5681000.tif\n",
      "  Attempting to process TIF: 22_Woodstock_339000_5682000.tif\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 3 polygons after clipping for 22_Woodstock_339000_5682000.tif.\n",
      "    Processing TIF: 22_Woodstock_339000_5682000.tif for dataset (Image ID: 3)\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_339000_5682000.tif\n",
      "DEBUG: For 22_Woodstock_339000_5682000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_339000_5682000.tif\n",
      "  Attempting to process TIF: 22_Woodstock_344000_5679000.tif\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 2 polygons after clipping for 22_Woodstock_344000_5679000.tif.\n",
      "    Processing TIF: 22_Woodstock_344000_5679000.tif for dataset (Image ID: 4)\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_344000_5679000.tif\n",
      "DEBUG: For 22_Woodstock_344000_5679000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_344000_5679000.tif\n",
      "  Attempting to process TIF: 22_Woodstock_346000_5681000.tif\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 1 polygons after clipping for 22_Woodstock_346000_5681000.tif.\n",
      "    Processing TIF: 22_Woodstock_346000_5681000.tif for dataset (Image ID: 5)\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_346000_5681000.tif\n",
      "DEBUG: For 22_Woodstock_346000_5681000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_346000_5681000.tif\n",
      "  Attempting to process TIF: 22_Woodstock_356000_5679000.tif\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - Rasterio original dimensions: 20000x20000\n",
      "    WARNING: CRS mismatch. Polygon CRS: EPSG:26916, Raster CRS: EPSG:3160. Attempting to reproject polygons.\n",
      "        Polygons reprojected successfully.\n",
      "    Found 2 polygons after clipping for 22_Woodstock_356000_5679000.tif.\n",
      "    Processing TIF: 22_Woodstock_356000_5679000.tif for dataset (Image ID: 6)\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - Calculated scaled dimensions: 10000x10000 (using scale_factor: 0.5)\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - CV2 opened original dimensions: 20000x20000\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - Entering scaling block. Target: 10000x10000. Resampling: cv2.INTER_AREA\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - CV2 resized dimensions (before save): 10000x10000\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - Attempting to save SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_356000_5679000.tif\n",
      "DEBUG: For 22_Woodstock_356000_5679000.tif - Successfully saved SCALED image using CV2 to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\images\\train\\22_Woodstock_356000_5679000.tif\n",
      "\n",
      "  Saved annotations to C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\\annotations\\instances_train.json\n",
      "\n",
      "Creating ZIP archive from contents of: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\n",
      "Archive will be saved as: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\archive.zip\n",
      "Successfully created ZIP archive: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\archive.zip\n",
      "COCO dataset creation finished at 2025-05-28 11:07:02\n",
      "\n",
      "--- SCRIPT FINISHED SUCCESSFULLY ---\n",
      "COCO dataset ZIP archive created at: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\archive.zip\n",
      "The contents of the ZIP (images/train/ and annotations/train.json) are from: C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random # Retained for potential future use, though shuffle isn't strictly needed for single dataset\n",
    "import shutil\n",
    "# from PIL import Image, ImageFile # REMOVED\n",
    "import cv2 # ADDED\n",
    "import numpy as np # ADDED\n",
    "from datetime import datetime\n",
    "from typing import List, Optional # Added for type hinting\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "import geopandas\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Allow loading of truncated images, can be common with some TIFFs\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True # REMOVED\n",
    "# FIX: Increase Pillow's maximum image pixels limit\n",
    "# Image.MAX_IMAGE_PIXELS = None # REMOVED\n",
    "\n",
    "def create_coco_dataset_no_arcpy(\n",
    "    tif_folder_path: str,\n",
    "    polygon_shapefile_path: str,\n",
    "    output_directory_path: str,\n",
    "    scale_factor: float = 1.0,\n",
    "    target_filenames: Optional[List[str]] = None,\n",
    "    coco_category_name: str = \"tree\",\n",
    "    coco_supercategory_name: str = \"natural_object\",\n",
    "    coco_license_name: str = \"User Defined\",\n",
    "    coco_license_url: str = \"\",\n",
    "    dataset_description: str = \"Custom COCO Dataset\",\n",
    "    contributor_name: str = \"GIS to COCO Script (No ArcPy)\",\n",
    "    resampling_method = cv2.INTER_AREA # CHANGED\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts TIF images and polygon annotations (from Shapefile)\n",
    "    into COCO dataset format without using ArcPy.\n",
    "    Optionally scales images and annotations.\n",
    "    Includes detailed debugging print statements for scaling.\n",
    "    Deletes TIFs from source if no corresponding polygons are found.\n",
    "    Outputs to a single 'train' set.\n",
    "    Can filter TIFs to process based on a provided list of filenames.\n",
    "    Clears and recreates the output directory to ensure a clean structure.\n",
    "    \"\"\"\n",
    "    print(f\"Starting COCO dataset creation (No ArcPy) at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"  TIF Folder: {tif_folder_path}\")\n",
    "    print(f\"  Polygon Shapefile: {polygon_shapefile_path}\")\n",
    "    print(f\"  Output Directory: {output_directory_path}\")\n",
    "\n",
    "    # --- MODIFIED SECTION: Clean and prepare output directory ---\n",
    "    print(f\"  Preparing output directory: {output_directory_path}\")\n",
    "    if os.path.exists(output_directory_path):\n",
    "        print(f\"    WARNING: Output directory '{output_directory_path}' already exists.\")\n",
    "        print(f\"    It will be completely REMOVED to ensure a clean dataset generation.\")\n",
    "        user_confirmation = input(f\"    Type 'YES' to confirm deletion of '{output_directory_path}' and its contents: \")\n",
    "        if user_confirmation == 'YES':\n",
    "            try:\n",
    "                shutil.rmtree(output_directory_path)\n",
    "                print(f\"    Successfully removed existing directory: '{output_directory_path}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR: Could not remove existing output directory '{output_directory_path}': {e}\")\n",
    "                print(f\"    Please manually clear this directory or check permissions and try again.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"    Aborted by user. Output directory was not cleared.\")\n",
    "            return None # Or raise an error, or ask for a new path\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_directory_path, exist_ok=False) # Create the root output directory; exist_ok=False to ensure it was indeed removed or didn't exist\n",
    "        print(f\"    Successfully created clean output directory: '{output_directory_path}'\")\n",
    "    except FileExistsError:\n",
    "        # This case should ideally not be hit if rmtree was successful and no race condition.\n",
    "        # If it is hit, it implies rmtree didn't fully work or something recreated it.\n",
    "        print(f\"    Output directory '{output_directory_path}' still exists unexpectedly after attempting removal. Please check.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Could not create output directory '{output_directory_path}': {e}\")\n",
    "        return None\n",
    "    # --- END OF MODIFIED SECTION ---\n",
    "\n",
    "    if target_filenames:\n",
    "        print(f\"  Processing only TIFs specified in target_filenames list ({len(target_filenames)} files).\")\n",
    "    if abs(scale_factor - 1.0) > 1e-9 :\n",
    "        print(f\"  Scaling Factor: {scale_factor}\")\n",
    "    else:\n",
    "        print(f\"  Scaling Factor: {scale_factor} (No significant scaling will be applied)\")\n",
    "\n",
    "    images_base_dir = os.path.join(output_directory_path, \"images\")\n",
    "    img_output_dir = os.path.join(images_base_dir, \"train\")\n",
    "    ann_dir = os.path.join(output_directory_path, \"annotations\")\n",
    "\n",
    "    print(f\"  Creating necessary sub-directory structure within '{output_directory_path}'...\")\n",
    "    try:\n",
    "        # os.makedirs(images_base_dir, exist_ok=True) # Redundant if img_output_dir is created\n",
    "        os.makedirs(img_output_dir, exist_ok=True)   # This will create output_directory_path/images/train\n",
    "        os.makedirs(ann_dir, exist_ok=True)          # This will create output_directory_path/annotations\n",
    "        print(f\"    Successfully created sub-directory structure.\")\n",
    "        print(f\"      Images will be in: {img_output_dir}\")\n",
    "        print(f\"      Annotations will be in: {ann_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Could not create sub-directory structure: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    base_coco_structure = {\n",
    "        \"info\": {\n",
    "            \"description\": dataset_description, \"version\": \"1.0\", \"year\": datetime.now().year,\n",
    "            \"contributor\": contributor_name, \"date_created\": datetime.now().isoformat()\n",
    "        },\n",
    "        \"licenses\": [{\"id\": 1, \"name\": coco_license_name, \"url\": coco_license_url}],\n",
    "        \"categories\": [{\"id\": 1, \"name\": coco_category_name, \"supercategory\": coco_supercategory_name}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"  Loading polygons from: {polygon_shapefile_path}\")\n",
    "        all_polygons_gdf = geopandas.read_file(polygon_shapefile_path)\n",
    "        print(f\"    Loaded {len(all_polygons_gdf)} polygons.\")\n",
    "        if all_polygons_gdf.crs is None:\n",
    "            print(\"    WARNING: Polygon shapefile has no CRS defined. Assuming it matches raster CRS.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Could not read polygon shapefile: {e}\")\n",
    "        return None\n",
    "\n",
    "    def world_to_pixel_affine(geo_x, geo_y, affine_transform: Affine):\n",
    "        col, row = ~affine_transform * (geo_x, geo_y)\n",
    "        return col, row\n",
    "\n",
    "    all_tif_files_in_folder = [f for f in os.listdir(tif_folder_path) if f.lower().endswith((\".tif\", \".tiff\"))]\n",
    "    if not all_tif_files_in_folder:\n",
    "        print(\"ERROR: No TIF files found in the input folder.\")\n",
    "        return None\n",
    "\n",
    "    if target_filenames:\n",
    "        print(f\"  Filtering TIFs based on the provided list of {len(target_filenames)} filenames.\")\n",
    "        target_filenames_set = {os.path.basename(f) for f in target_filenames}\n",
    "\n",
    "        files_in_folder_set = set(all_tif_files_in_folder)\n",
    "        missing_targets = target_filenames_set - files_in_folder_set\n",
    "        if missing_targets:\n",
    "            print(f\"      WARNING: The following {len(missing_targets)} target filenames were not found in {tif_folder_path}: {sorted(list(missing_targets))}\")\n",
    "\n",
    "        processed_tif_files = [f for f in all_tif_files_in_folder if os.path.basename(f) in target_filenames_set]\n",
    "\n",
    "        print(f\"      Found {len(processed_tif_files)} matching TIFs to process out of {len(all_tif_files_in_folder)} in the folder.\")\n",
    "        if not processed_tif_files:\n",
    "            print(\"ERROR: No TIF files from the target list were found in the input folder. No images to process.\")\n",
    "            # Create empty annotation file and zip as per previous logic if this path is taken.\n",
    "            # Fall through to the empty dataset handling.\n",
    "    else:\n",
    "        processed_tif_files = all_tif_files_in_folder\n",
    "        print(f\"  Processing all {len(processed_tif_files)} TIF files found in the folder.\")\n",
    "\n",
    "    coco_data = json.loads(json.dumps(base_coco_structure))\n",
    "    coco_data[\"images\"], coco_data[\"annotations\"] = [], []\n",
    "    global_image_id_counter, global_annotation_id_counter = 0, 0\n",
    "\n",
    "    print(f\"\\nProcessing images...\")\n",
    "\n",
    "    for tif_filename in processed_tif_files:\n",
    "        tif_full_path = os.path.join(tif_folder_path, tif_filename)\n",
    "        print(f\"  Attempting to process TIF: {tif_filename}\")\n",
    "        original_img_width, original_img_height = 0, 0\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(tif_full_path) as src_raster:\n",
    "                original_img_width = src_raster.width\n",
    "                original_img_height = src_raster.height\n",
    "                print(f\"DEBUG: For {tif_filename} - Rasterio original dimensions: {original_img_width}x{original_img_height}\")\n",
    "                raster_transform = src_raster.transform\n",
    "                raster_bounds = src_raster.bounds\n",
    "                raster_crs = src_raster.crs\n",
    "\n",
    "            polygons_gdf_for_raster = all_polygons_gdf\n",
    "            if all_polygons_gdf.crs and raster_crs and not all_polygons_gdf.crs.equals(raster_crs):\n",
    "                print(f\"    WARNING: CRS mismatch. Polygon CRS: {all_polygons_gdf.crs}, Raster CRS: {raster_crs}. Attempting to reproject polygons.\")\n",
    "                try:\n",
    "                    polygons_gdf_for_raster = all_polygons_gdf.to_crs(raster_crs)\n",
    "                    print(\"        Polygons reprojected successfully.\")\n",
    "                except Exception as reproj_e:\n",
    "                    print(f\"        ERROR: Failed to reproject polygons for {tif_filename}: {reproj_e}. Skipping this TIF.\")\n",
    "                    continue\n",
    "            elif all_polygons_gdf.crs is None and raster_crs is not None:\n",
    "                print(f\"    WARNING: Polygons have no CRS. Assuming they match raster CRS for {tif_filename}: {raster_crs}.\")\n",
    "\n",
    "            clip_box_geom = box(raster_bounds.left, raster_bounds.bottom, raster_bounds.right, raster_bounds.top)\n",
    "            try:\n",
    "                clip_mask_gdf = geopandas.GeoDataFrame({'geometry': [clip_box_geom]}, crs=raster_crs if raster_crs else polygons_gdf_for_raster.crs)\n",
    "                clipped_polygons_gdf = geopandas.clip(polygons_gdf_for_raster, clip_mask_gdf)\n",
    "            except Exception as clip_e:\n",
    "                print(f\"    ERROR during geopandas.clip for {tif_filename}: {clip_e}. Skipping annotations for this TIF.\")\n",
    "                clipped_polygons_gdf = geopandas.GeoDataFrame(columns=['geometry'])\n",
    "\n",
    "            if clipped_polygons_gdf.empty:\n",
    "                print(f\"    No polygons found within the bounds of {tif_filename} after clipping.\")\n",
    "                print(f\"    DELETING TIF file (no corresponding polygons): {tif_full_path}\")\n",
    "                try:\n",
    "                    os.remove(tif_full_path)\n",
    "                    print(f\"        Successfully deleted {tif_filename}.\")\n",
    "                except OSError as e:\n",
    "                    print(f\"        ERROR: Could not delete {tif_filename}: {e}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"    Found {len(clipped_polygons_gdf)} polygons after clipping for {tif_filename}.\")\n",
    "\n",
    "            global_image_id_counter += 1\n",
    "            current_image_id = global_image_id_counter\n",
    "            print(f\"    Processing TIF: {tif_filename} for dataset (Image ID: {current_image_id})\")\n",
    "\n",
    "            scaled_img_width = int(original_img_width * scale_factor)\n",
    "            scaled_img_height = int(original_img_height * scale_factor)\n",
    "            print(f\"DEBUG: For {tif_filename} - Calculated scaled dimensions: {scaled_img_width}x{scaled_img_height} (using scale_factor: {scale_factor})\")\n",
    "\n",
    "            coco_data[\"images\"].append({\n",
    "                \"id\": current_image_id, \"file_name\": tif_filename,\n",
    "                \"width\": scaled_img_width, \"height\": scaled_img_height,\n",
    "                \"license\": 1, \"date_captured\": \"\"\n",
    "            })\n",
    "\n",
    "            for _, poly_row in clipped_polygons_gdf.iterrows():\n",
    "                polygon_geom_shapely = poly_row.geometry\n",
    "                map_unit_area = polygon_geom_shapely.area\n",
    "                if polygon_geom_shapely.is_empty or not polygon_geom_shapely.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                    continue\n",
    "                global_annotation_id_counter += 1\n",
    "                coco_segments_for_ann = []\n",
    "                all_scaled_pixel_coords_x, all_scaled_pixel_coords_y = [], []\n",
    "                geoms_to_process = []\n",
    "                if polygon_geom_shapely.geom_type == 'Polygon':\n",
    "                    geoms_to_process.append(polygon_geom_shapely)\n",
    "                elif polygon_geom_shapely.geom_type == 'MultiPolygon':\n",
    "                    geoms_to_process.extend(list(polygon_geom_shapely.geoms))\n",
    "\n",
    "                for single_poly_shapely in geoms_to_process:\n",
    "                    exterior_coords = list(single_poly_shapely.exterior.coords)\n",
    "                    current_part_scaled_pixels_ext = []\n",
    "                    for coord_tuple in exterior_coords:\n",
    "                        geo_x, geo_y = coord_tuple[0], coord_tuple[1]\n",
    "                        original_pixel_x, original_pixel_y = world_to_pixel_affine(geo_x, geo_y, raster_transform)\n",
    "                        scaled_pixel_x = original_pixel_x * scale_factor\n",
    "                        scaled_pixel_y = original_pixel_y * scale_factor\n",
    "                        clamped_scaled_x = max(0.0, min(scaled_pixel_x, float(scaled_img_width)))\n",
    "                        clamped_scaled_y = max(0.0, min(scaled_pixel_y, float(scaled_img_height)))\n",
    "                        current_part_scaled_pixels_ext.extend([clamped_scaled_x, clamped_scaled_y])\n",
    "                        all_scaled_pixel_coords_x.append(clamped_scaled_x)\n",
    "                        all_scaled_pixel_coords_y.append(clamped_scaled_y)\n",
    "                    if current_part_scaled_pixels_ext:\n",
    "                        coco_segments_for_ann.append(current_part_scaled_pixels_ext)\n",
    "\n",
    "                    for interior_ring in single_poly_shapely.interiors:\n",
    "                        interior_coords = list(interior_ring.coords)\n",
    "                        current_part_scaled_pixels_int = []\n",
    "                        for coord_tuple in interior_coords:\n",
    "                            geo_x, geo_y = coord_tuple[0], coord_tuple[1]\n",
    "                            original_pixel_x, original_pixel_y = world_to_pixel_affine(geo_x, geo_y, raster_transform)\n",
    "                            scaled_pixel_x = original_pixel_x * scale_factor\n",
    "                            scaled_pixel_y = original_pixel_y * scale_factor\n",
    "                            clamped_scaled_x = max(0.0, min(scaled_pixel_x, float(scaled_img_width)))\n",
    "                            clamped_scaled_y = max(0.0, min(scaled_pixel_y, float(scaled_img_height)))\n",
    "                            current_part_scaled_pixels_int.extend([clamped_scaled_x, clamped_scaled_y])\n",
    "                            all_scaled_pixel_coords_x.append(clamped_scaled_x)\n",
    "                            all_scaled_pixel_coords_y.append(clamped_scaled_y)\n",
    "                        if current_part_scaled_pixels_int:\n",
    "                            coco_segments_for_ann.append(current_part_scaled_pixels_int)\n",
    "\n",
    "                if not coco_segments_for_ann or not all_scaled_pixel_coords_x: continue\n",
    "                min_x_s = min(all_scaled_pixel_coords_x)\n",
    "                min_y_s = min(all_scaled_pixel_coords_y)\n",
    "                max_x_s = max(all_scaled_pixel_coords_x)\n",
    "                max_y_s = max(all_scaled_pixel_coords_y)\n",
    "                bbox_coco_scaled = [min_x_s, min_y_s, max_x_s - min_x_s, max_y_s - min_y_s]\n",
    "                pixel_area_on_map_sq = abs(raster_transform.a * raster_transform.e)\n",
    "                original_pixel_area = (map_unit_area / pixel_area_on_map_sq) if pixel_area_on_map_sq > 1e-9 else 0\n",
    "                scaled_pixel_area = original_pixel_area * (scale_factor ** 2)\n",
    "                coco_data[\"annotations\"].append({\n",
    "                    \"id\": global_annotation_id_counter, \"image_id\": current_image_id, \"category_id\": 1,\n",
    "                    \"segmentation\": coco_segments_for_ann, \"area\": scaled_pixel_area,\n",
    "                    \"bbox\": bbox_coco_scaled, \"iscrowd\": 0\n",
    "                })\n",
    "\n",
    "            # --- MODIFIED IMAGE HANDLING SECTION ---\n",
    "            cv2_img_original = cv2.imread(tif_full_path, cv2.IMREAD_UNCHANGED)\n",
    "            if cv2_img_original is None:\n",
    "                 print(f\"    ERROR: CV2 could not open or read {tif_filename}. Skipping image save. JSON entry will remain but image file will be missing.\")\n",
    "                 continue # Skip to the next TIF file\n",
    "\n",
    "            h, w = cv2_img_original.shape[:2]\n",
    "            print(f\"DEBUG: For {tif_filename} - CV2 opened original dimensions: {w}x{h}\")\n",
    "            destination_image_path = os.path.join(img_output_dir, tif_filename)\n",
    "\n",
    "            if abs(scale_factor - 1.0) < 1e-9:\n",
    "                print(f\"DEBUG: For {tif_filename} - Copying image, no scaling. Path: {destination_image_path}\")\n",
    "                shutil.copy2(tif_full_path, destination_image_path)\n",
    "            else:\n",
    "                print(f\"DEBUG: For {tif_filename} - Entering scaling block. Target: {scaled_img_width}x{scaled_img_height}. Resampling: cv2.INTER_AREA\")\n",
    "                scaled_img_cv2 = cv2.resize(cv2_img_original, (scaled_img_width, scaled_img_height), interpolation=resampling_method)\n",
    "                sh, sw = scaled_img_cv2.shape[:2]\n",
    "                print(f\"DEBUG: For {tif_filename} - CV2 resized dimensions (before save): {sw}x{sh}\")\n",
    "                try:\n",
    "                    print(f\"DEBUG: For {tif_filename} - Attempting to save SCALED image using CV2 to {destination_image_path}\")\n",
    "                    success = cv2.imwrite(destination_image_path, scaled_img_cv2)\n",
    "                    if success:\n",
    "                        print(f\"DEBUG: For {tif_filename} - Successfully saved SCALED image using CV2 to {destination_image_path}\")\n",
    "                    else:\n",
    "                        print(f\"    ERROR: Could not save scaled {tif_filename} using CV2 (imwrite returned False).\")\n",
    "                except Exception as save_e:\n",
    "                    print(f\"    ERROR: Could not save {tif_filename} using CV2 after scaling: {save_e}.\")\n",
    "            # No close needed for cv2.imread\n",
    "            # --- END OF MODIFIED IMAGE HANDLING SECTION ---\n",
    "\n",
    "        except rasterio.errors.RasterioIOError as rio_e:\n",
    "            print(f\"    ERROR: Rasterio could not open or read {tif_filename}: {rio_e}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"    ERROR: File not found for processing (was it moved/deleted?): {tif_full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR processing file {tif_filename}: {e.__class__.__name__} - {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    if not coco_data[\"images\"]:\n",
    "        print(\"\\nWARNING: No images were processed and added to the dataset. This could be due to:\")\n",
    "        print(\"  - All TIFs lacked corresponding polygons and were deleted.\")\n",
    "        print(\"  - The target_filenames list (if provided) resulted in no processable TIFs.\")\n",
    "        print(\"  - Other errors during processing of all TIFs.\")\n",
    "        print(\"An empty 'train.json' will be created, and the ZIP archive may be empty or incomplete.\")\n",
    "\n",
    "    output_json_filename = os.path.join(ann_dir, \"instances_train.json\")\n",
    "    with open(output_json_filename, 'w') as f: json.dump(coco_data, f, indent=4)\n",
    "    print(f\"\\n  Saved annotations to {output_json_filename}\")\n",
    "\n",
    "    parent_dir_of_output = os.path.dirname(output_directory_path.rstrip(os.sep))\n",
    "    if not parent_dir_of_output:\n",
    "        parent_dir_of_output = \".\"\n",
    "    archive_base_name = os.path.join(parent_dir_of_output, \"archive\")\n",
    "\n",
    "    print(f\"\\nCreating ZIP archive from contents of: {output_directory_path}\")\n",
    "    print(f\"Archive will be saved as: {archive_base_name}.zip\")\n",
    "\n",
    "    try:\n",
    "        zip_output_path = shutil.make_archive(\n",
    "            base_name=archive_base_name,\n",
    "            format='zip',\n",
    "            root_dir=output_directory_path\n",
    "        )\n",
    "        print(f\"Successfully created ZIP archive: {zip_output_path}\")\n",
    "        return zip_output_path\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR creating ZIP archive: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # If zipping fails but data was generated, output_directory_path still contains the data\n",
    "        print(f\"Data was generated in '{output_directory_path}' but zipping failed.\")\n",
    "        return None # Or return output_directory_path to indicate partial success\n",
    "    finally:\n",
    "        print(f\"COCO dataset creation finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- USER CONFIGURATION ---\n",
    "    input_tifs_folder = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\TIFFS\"\n",
    "    input_polygon_shp = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\Woodstock Lake ArcGIS merged final.shp\"\n",
    "    output_coco_dir = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2022_woodstock\\coco\"  # MODIFY THIS\n",
    "\n",
    "    image_annotation_scale_factor = .5\n",
    "\n",
    "    category = \"fallen\" # Example: more specific category\n",
    "    super_category = \"tree\" # Example\n",
    "    description = \"Dataset of tree damage from drone imagery for COCO.\"\n",
    "    contributor = \"Automated Script\"\n",
    "    license_nm = \"CC0 - Public Domain\"\n",
    "    license_link = \"https://creativecommons.org/publicdomain/zero/1.0/\"\n",
    "\n",
    "    # target_tifs = [\"DJI_0001.TIF\", \"DJI_0002.TIF\"]\n",
    "    target_tifs = None\n",
    "\n",
    "    try:\n",
    "        generated_zip_file = create_coco_dataset_no_arcpy(\n",
    "            tif_folder_path=input_tifs_folder,\n",
    "            polygon_shapefile_path=input_polygon_shp,\n",
    "            output_directory_path=output_coco_dir,\n",
    "            scale_factor=image_annotation_scale_factor,\n",
    "            target_filenames=target_tifs,\n",
    "            coco_category_name=category,\n",
    "            coco_supercategory_name=super_category,\n",
    "            dataset_description=description,\n",
    "            contributor_name=contributor,\n",
    "            coco_license_name=license_nm,\n",
    "            coco_license_url=license_link\n",
    "            # No need to pass resampling_method, it uses the new cv2 default\n",
    "        )\n",
    "\n",
    "        if generated_zip_file:\n",
    "            print(f\"\\n--- SCRIPT FINISHED SUCCESSFULLY ---\")\n",
    "            print(f\"COCO dataset ZIP archive created at: {generated_zip_file}\")\n",
    "            print(f\"The contents of the ZIP (images/train/ and annotations/train.json) are from: {output_coco_dir}\")\n",
    "        else:\n",
    "            print(f\"\\n--- SCRIPT FINISHED WITH ERRORS OR NO IMAGES PROCESSED ---\")\n",
    "            print(f\"COCO dataset generation may have failed or produced an empty/incomplete dataset. Please review the logs.\")\n",
    "            if os.path.exists(output_coco_dir) and any(os.scandir(output_coco_dir)):\n",
    "                 print(f\"Intermediate files might be present in: {output_coco_dir}\")\n",
    "\n",
    "\n",
    "    except ImportError as ie:\n",
    "        print(f\"An import error occurred: {ie}\")\n",
    "        print(\"Please ensure you have installed all required libraries:\")\n",
    "        print(\"pip install rasterio geopandas shapely opencv-python pyproj\") # MODIFIED\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in the main execution block: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-checked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
