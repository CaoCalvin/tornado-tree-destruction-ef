{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageFile\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "import geopandas\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Allow loading of truncated images, can be common with some TIFFs\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# FIX: Increase Pillow's maximum image pixels limit\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def create_coco_dataset_no_arcpy(\n",
    "    tif_folder_path: str,\n",
    "    polygon_shapefile_path: str,\n",
    "    output_directory_path: str,\n",
    "    include_tifs_list: Optional[List[str]] = None, # New parameter\n",
    "    scale_factor: float = 1.0,\n",
    "    coco_category_name: str = \"tree\",\n",
    "    coco_supercategory_name: str = \"natural_object\",\n",
    "    coco_license_name: str = \"User Defined\",\n",
    "    coco_license_url: str = \"\",\n",
    "    dataset_description: str = \"Custom COCO Dataset\",\n",
    "    contributor_name: str = \"GIS to COCO Script (No ArcPy)\",\n",
    "    resampling_method = Image.Resampling.LANCZOS # Ensure Pillow 9.1.0+\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts TIF images and polygon annotations (from Shapefile)\n",
    "    into COCO dataset format without using ArcPy.\n",
    "    Optionally filters TIFs to include only those in include_tifs_list.\n",
    "    Deletes original TIFs from tif_folder_path if no intersecting polygons are found.\n",
    "    All included images are placed in a single image folder, and a single annotation JSON is created.\n",
    "    Optionally scales images and annotations.\n",
    "    Adds a default \"unlabelled\" polygon to all included images.\n",
    "    \"\"\"\n",
    "    print(f\"Starting COCO dataset creation (No ArcPy) at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"  TIF Folder: {tif_folder_path}\")\n",
    "    print(f\"  Polygon Shapefile: {polygon_shapefile_path}\")\n",
    "    print(f\"  Output Directory: {output_directory_path}\")\n",
    "    if include_tifs_list:\n",
    "        print(f\"  Including only specified TIFs: {len(include_tifs_list)} files listed.\")\n",
    "    else:\n",
    "        print(\"  Processing all TIFs found in the folder.\")\n",
    "\n",
    "    if abs(scale_factor - 1.0) > 1e-9 : # Robust float comparison\n",
    "        print(f\"  Scaling Factor: {scale_factor}\")\n",
    "    else:\n",
    "        print(f\"  Scaling Factor: {scale_factor} (No significant scaling will be applied)\")\n",
    "\n",
    "    images_output_dir = os.path.join(output_directory_path, \"images\")\n",
    "    annotations_output_dir = os.path.join(output_directory_path, \"annotations\")\n",
    "\n",
    "    for dir_path in [output_directory_path, images_output_dir, annotations_output_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    main_category_id = 1\n",
    "    unlabelled_category_id = 2\n",
    "    unlabelled_category_name = \"unlabelled\"\n",
    "    unlabelled_supercategory_name = \"background\"\n",
    "\n",
    "    coco_data = {\n",
    "        \"info\": {\n",
    "            \"description\": dataset_description, \"version\": \"1.0\", \"year\": datetime.now().year,\n",
    "            \"contributor\": contributor_name, \"date_created\": datetime.now().isoformat()\n",
    "        },\n",
    "        \"licenses\": [{\"id\": 1, \"name\": coco_license_name, \"url\": coco_license_url}],\n",
    "        \"categories\": [\n",
    "            {\"id\": main_category_id, \"name\": coco_category_name, \"supercategory\": coco_supercategory_name},\n",
    "            {\"id\": unlabelled_category_id, \"name\": unlabelled_category_name, \"supercategory\": unlabelled_supercategory_name}\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"  Loading polygons from: {polygon_shapefile_path}\")\n",
    "        all_polygons_gdf = geopandas.read_file(polygon_shapefile_path)\n",
    "        print(f\"    Loaded {len(all_polygons_gdf)} polygons.\")\n",
    "        if all_polygons_gdf.crs is None:\n",
    "            print(\"    WARNING: Polygon shapefile has no CRS defined. Assuming it matches raster CRS.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Could not read polygon shapefile: {e}\")\n",
    "        return None\n",
    "\n",
    "    def world_to_pixel_affine(geo_x, geo_y, affine_transform: Affine):\n",
    "        col, row = ~affine_transform * (geo_x, geo_y)\n",
    "        return col, row\n",
    "\n",
    "    # Determine which TIF files to consider\n",
    "    if include_tifs_list:\n",
    "        # User provided a specific list of TIF basenames\n",
    "        all_tif_files_to_check = [\n",
    "            f for f in include_tifs_list if os.path.exists(os.path.join(tif_folder_path, f))\n",
    "        ]\n",
    "        if len(all_tif_files_to_check) != len(include_tifs_list):\n",
    "            print(\"  WARNING: Some TIFs in include_tifs_list were not found in tif_folder_path.\")\n",
    "        if not all_tif_files_to_check:\n",
    "            print(f\"ERROR: No TIF files from the provided list found in {tif_folder_path}.\")\n",
    "            return None\n",
    "        print(f\"  Will attempt to process {len(all_tif_files_to_check)} TIFs from the provided list.\")\n",
    "    else:\n",
    "        # Scan the folder for all TIF files\n",
    "        all_tif_files_to_check = [f for f in os.listdir(tif_folder_path) if f.lower().endswith((\".tif\", \".tiff\"))]\n",
    "        if not all_tif_files_to_check:\n",
    "            print(f\"ERROR: No TIF files found in {tif_folder_path}.\")\n",
    "            return None\n",
    "        print(f\"  Found {len(all_tif_files_to_check)} TIF files in the folder to pre-filter.\")\n",
    "\n",
    "\n",
    "    valid_tif_files = []\n",
    "    # temp_image_details = {} # Not strictly needed for this version\n",
    "\n",
    "    print(\"\\nPre-filtering TIF files and deleting those without polygons...\")\n",
    "    for tif_filename_check in all_tif_files_to_check:\n",
    "        tif_full_path_check = os.path.join(tif_folder_path, tif_filename_check)\n",
    "        try:\n",
    "            with rasterio.open(tif_full_path_check) as src_raster_check:\n",
    "                raster_transform_check = src_raster_check.transform\n",
    "                raster_bounds_check = src_raster_check.bounds\n",
    "                raster_crs_check = src_raster_check.crs\n",
    "\n",
    "            polygons_gdf_for_raster_check = all_polygons_gdf\n",
    "            if all_polygons_gdf.crs and raster_crs_check and not all_polygons_gdf.crs.equals(raster_crs_check):\n",
    "                try:\n",
    "                    polygons_gdf_for_raster_check = all_polygons_gdf.to_crs(raster_crs_check)\n",
    "                except Exception as reproj_err_check:\n",
    "                    print(f\"    WARNING: Could not reproject polygons for pre-filtering {tif_filename_check}: {reproj_err_check}. Skipping this file.\")\n",
    "                    continue\n",
    "            \n",
    "            clip_box_geom_check = box(raster_bounds_check.left, raster_bounds_check.bottom, raster_bounds_check.right, raster_bounds_check.top)\n",
    "            try:\n",
    "                clip_mask_gdf_check = geopandas.GeoDataFrame({'geometry': [clip_box_geom_check]}, crs=raster_crs_check)\n",
    "                clipped_polygons_gdf_check = geopandas.clip(polygons_gdf_for_raster_check, clip_mask_gdf_check)\n",
    "            except Exception as clip_e:\n",
    "                print(f\"    WARNING: Error during geopandas.clip for pre-filtering {tif_filename_check}: {clip_e}. Skipping this file.\")\n",
    "                continue\n",
    "            \n",
    "            if clipped_polygons_gdf_check.empty:\n",
    "                print(f\"  INFO: {tif_filename_check} has ZERO existing polygons from the shapefile.\")\n",
    "                try:\n",
    "                    os.remove(tif_full_path_check)\n",
    "                    print(f\"    DELETED original TIF: {tif_full_path_check}\")\n",
    "                except OSError as e_remove:\n",
    "                    print(f\"    ERROR: Could not delete TIF {tif_full_path_check}: {e_remove}\")\n",
    "            else:\n",
    "                print(f\"  INFO: {tif_filename_check} has {len(clipped_polygons_gdf_check)} polygons. Will be included.\")\n",
    "                valid_tif_files.append(tif_filename_check)\n",
    "                # temp_image_details[tif_filename_check] = {\n",
    "                # 'width': src_raster_check.width, # Not opening again, so store if needed\n",
    "                # 'height': src_raster_check.height,\n",
    "                # 'transform': raster_transform_check,\n",
    "                # 'bounds': raster_bounds_check,\n",
    "                # 'crs': raster_crs_check\n",
    "                # }\n",
    "\n",
    "        except rasterio.errors.RasterioIOError as rio_e:\n",
    "            print(f\"    ERROR: Rasterio could not open or read {tif_filename_check} during pre-filtering: {rio_e}. Skipping.\")\n",
    "        except Exception as e_check:\n",
    "            print(f\"    ERROR pre-filtering file {tif_filename_check}: {e_check.__class__.__name__} - {e_check}. Skipping.\")\n",
    "\n",
    "    if not valid_tif_files:\n",
    "        print(\"ERROR: No TIF files found with overlapping polygons (or none left after filtering). Cannot create dataset.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nTotal TIF files considered for processing: {len(all_tif_files_to_check)}\")\n",
    "    print(f\"TIF files to be included in COCO dataset: {len(valid_tif_files)}\")\n",
    "\n",
    "    random.shuffle(valid_tif_files) # Shuffle for potentially random processing order\n",
    "\n",
    "    global_image_id_counter, global_annotation_id_counter = 0, 0\n",
    "\n",
    "    print(f\"\\nProcessing {len(valid_tif_files)} images for the dataset...\")\n",
    "\n",
    "    for tif_filename in valid_tif_files:\n",
    "        global_image_id_counter += 1 \n",
    "        current_image_id = global_image_id_counter\n",
    "        print(f\"  Processing TIF: {tif_filename} (Image ID: {current_image_id})\")\n",
    "\n",
    "        tif_full_path = os.path.join(tif_folder_path, tif_filename)\n",
    "        original_img_width, original_img_height = 0, 0\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(tif_full_path) as src_raster:\n",
    "                original_img_width = src_raster.width\n",
    "                original_img_height = src_raster.height\n",
    "                print(f\"DEBUG: For {tif_filename} - Rasterio original dimensions: {original_img_width}x{original_img_height}\")\n",
    "                raster_transform = src_raster.transform\n",
    "                raster_bounds = src_raster.bounds\n",
    "                raster_crs = src_raster.crs\n",
    "\n",
    "            polygons_gdf_for_raster = all_polygons_gdf\n",
    "            if all_polygons_gdf.crs and raster_crs and not all_polygons_gdf.crs.equals(raster_crs):\n",
    "                print(f\"    WARNING: CRS mismatch. Polygon CRS: {all_polygons_gdf.crs}, Raster CRS: {raster_crs}. Attempting to reproject polygons.\")\n",
    "                try:\n",
    "                    polygons_gdf_for_raster = all_polygons_gdf.to_crs(raster_crs)\n",
    "                    print(\"      Polygons reprojected successfully.\")\n",
    "                except Exception as reproj_e:\n",
    "                    print(f\"      ERROR: Failed to reproject polygons for {tif_filename}: {reproj_e}. Skipping specific annotations for this TIF, but image and 'unlabelled' will be added.\")\n",
    "                    clipped_polygons_gdf = geopandas.GeoDataFrame(columns=['geometry'], crs=raster_crs) # Empty GDF\n",
    "            elif all_polygons_gdf.crs is None and raster_crs is not None:\n",
    "                print(f\"    WARNING: Polygons have no CRS. Assuming they match raster CRS: {raster_crs}.\")\n",
    "            \n",
    "            scaled_img_width = int(original_img_width * scale_factor)\n",
    "            scaled_img_height = int(original_img_height * scale_factor)\n",
    "            print(f\"DEBUG: For {tif_filename} - Calculated scaled dimensions: {scaled_img_width}x{scaled_img_height} (using scale_factor: {scale_factor})\")\n",
    "\n",
    "            coco_data[\"images\"].append({\n",
    "                \"id\": current_image_id, \"file_name\": tif_filename,\n",
    "                \"width\": scaled_img_width, \"height\": scaled_img_height,\n",
    "                \"license\": 1, \"date_captured\": \"\"\n",
    "            })\n",
    "\n",
    "            clip_box_geom = box(raster_bounds.left, raster_bounds.bottom, raster_bounds.right, raster_bounds.top)\n",
    "            try:\n",
    "                clip_mask_gdf = geopandas.GeoDataFrame({'geometry': [clip_box_geom]}, crs=raster_crs)\n",
    "                # Ensure polygons_gdf_for_raster is valid before clipping\n",
    "                if not polygons_gdf_for_raster.empty and 'geometry' in polygons_gdf_for_raster.columns:\n",
    "                     clipped_polygons_gdf = geopandas.clip(polygons_gdf_for_raster, clip_mask_gdf)\n",
    "                else:\n",
    "                    print(f\"    INFO: No polygons to clip for {tif_filename} (possibly due to earlier reprojection failure).\")\n",
    "                    clipped_polygons_gdf = geopandas.GeoDataFrame(columns=['geometry'], crs=raster_crs) # Empty GDF\n",
    "\n",
    "            except Exception as clip_e:\n",
    "                print(f\"    ERROR during geopandas.clip for {tif_filename}: {clip_e}. No specific annotations will be added.\")\n",
    "                clipped_polygons_gdf = geopandas.GeoDataFrame(columns=['geometry'], crs=raster_crs) # Empty GDF\n",
    "\n",
    "            # Process existing polygons if any (category_id = main_category_id)\n",
    "            if not clipped_polygons_gdf.empty:\n",
    "                print(f\"     Found {len(clipped_polygons_gdf)} specific polygons after clipping for {tif_filename}.\")\n",
    "                for _, poly_row in clipped_polygons_gdf.iterrows():\n",
    "                    polygon_geom_shapely = poly_row.geometry\n",
    "                    \n",
    "                    if polygon_geom_shapely.is_empty or not polygon_geom_shapely.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                        print(f\"DEBUG: Skipping empty or invalid geometry type ({polygon_geom_shapely.geom_type}) in {tif_filename}.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # map_unit_area is critical for area calculation.\n",
    "                    # Ensure it's a valid number.\n",
    "                    map_unit_area = 0.0\n",
    "                    if hasattr(polygon_geom_shapely, 'area'):\n",
    "                        map_unit_area = polygon_geom_shapely.area\n",
    "                        if not isinstance(map_unit_area, (int, float)) or map_unit_area != map_unit_area: # Check for NaN\n",
    "                            print(f\"     WARNING: map_unit_area is NaN or invalid for a polygon in {tif_filename}. Setting to 0.\")\n",
    "                            map_unit_area = 0.0\n",
    "                    else:\n",
    "                        print(f\"     WARNING: polygon_geom_shapely has no 'area' attribute for a polygon in {tif_filename}. Setting map_unit_area to 0.\")\n",
    "\n",
    "\n",
    "                    global_annotation_id_counter += 1\n",
    "                    current_annotation_id = global_annotation_id_counter # Store current ID for clarity\n",
    "\n",
    "                    coco_segments_for_ann = []\n",
    "                    all_scaled_pixel_coords_x, all_scaled_pixel_coords_y = [], []\n",
    "                    geoms_to_process = []\n",
    "                    if polygon_geom_shapely.geom_type == 'Polygon':\n",
    "                        geoms_to_process.append(polygon_geom_shapely)\n",
    "                    elif polygon_geom_shapely.geom_type == 'MultiPolygon':\n",
    "                        geoms_to_process.extend(list(polygon_geom_shapely.geoms))\n",
    "\n",
    "                    for single_poly_shapely in geoms_to_process:\n",
    "                        if single_poly_shapely.is_empty: # Additional check for parts of MultiPolygon\n",
    "                            continue\n",
    "                        exterior_coords_raw = list(single_poly_shapely.exterior.coords)\n",
    "                        current_part_scaled_pixels_ext = []\n",
    "                        for coord_tuple in exterior_coords_raw:\n",
    "                            geo_x, geo_y = coord_tuple[:2]\n",
    "                            original_pixel_x, original_pixel_y = world_to_pixel_affine(geo_x, geo_y, raster_transform)\n",
    "                            scaled_pixel_x = original_pixel_x * scale_factor\n",
    "                            scaled_pixel_y = original_pixel_y * scale_factor\n",
    "                            clamped_scaled_x = max(0.0, min(scaled_pixel_x, float(scaled_img_width)))\n",
    "                            clamped_scaled_y = max(0.0, min(scaled_pixel_y, float(scaled_img_height)))\n",
    "                            current_part_scaled_pixels_ext.extend([clamped_scaled_x, clamped_scaled_y])\n",
    "                            all_scaled_pixel_coords_x.append(clamped_scaled_x)\n",
    "                            all_scaled_pixel_coords_y.append(clamped_scaled_y)\n",
    "                        \n",
    "                        # A valid COCO polygon segment needs at least 3 points (6 coordinates)\n",
    "                        if len(current_part_scaled_pixels_ext) >= 6:\n",
    "                            coco_segments_for_ann.append(current_part_scaled_pixels_ext)\n",
    "                        else:\n",
    "                            print(f\"DEBUG: Exterior segment for ann ID {current_annotation_id} in {tif_filename} has < 3 points after scaling/clamping. Skipping this segment part.\")\n",
    "\n",
    "                        for interior_ring in single_poly_shapely.interiors:\n",
    "                            if interior_ring.is_empty: continue\n",
    "                            interior_coords_raw = list(interior_ring.coords)\n",
    "                            current_part_scaled_pixels_int = []\n",
    "                            for coord_tuple in interior_coords_raw:\n",
    "                                geo_x, geo_y = coord_tuple[:2]\n",
    "                                original_pixel_x, original_pixel_y = world_to_pixel_affine(geo_x, geo_y, raster_transform)\n",
    "                                scaled_pixel_x = original_pixel_x * scale_factor\n",
    "                                scaled_pixel_y = original_pixel_y * scale_factor\n",
    "                                clamped_scaled_x = max(0.0, min(scaled_pixel_x, float(scaled_img_width)))\n",
    "                                clamped_scaled_y = max(0.0, min(scaled_pixel_y, float(scaled_img_height)))\n",
    "                                current_part_scaled_pixels_int.extend([clamped_scaled_x, clamped_scaled_y])\n",
    "                                # Bounding box should include interior ring points as well if they extend beyond exterior\n",
    "                                all_scaled_pixel_coords_x.append(clamped_scaled_x)\n",
    "                                all_scaled_pixel_coords_y.append(clamped_scaled_y)\n",
    "                            \n",
    "                            if len(current_part_scaled_pixels_int) >= 6:\n",
    "                                coco_segments_for_ann.append(current_part_scaled_pixels_int)\n",
    "                            else:\n",
    "                                print(f\"DEBUG: Interior segment for ann ID {current_annotation_id} in {tif_filename} has < 3 points. Skipping this segment part.\")\n",
    "                    \n",
    "                    # If after processing all parts, there are no valid segments or coordinates for bbox:\n",
    "                    if not coco_segments_for_ann or not all_scaled_pixel_coords_x or not all_scaled_pixel_coords_y:\n",
    "                        print(f\"     INFO: Ann ID {current_annotation_id} for {tif_filename} resulted in no valid segmentation data or bbox coords after processing. Skipping this annotation.\")\n",
    "                        # Decrement counter as this annotation ID won't be used\n",
    "                        global_annotation_id_counter -= 1 # Revert increment if annotation is skipped\n",
    "                        continue\n",
    "\n",
    "                    # --- Bounding Box Calculation ---\n",
    "                    min_x_s = min(all_scaled_pixel_coords_x)\n",
    "                    min_y_s = min(all_scaled_pixel_coords_y)\n",
    "                    max_x_s = max(all_scaled_pixel_coords_x)\n",
    "                    max_y_s = max(all_scaled_pixel_coords_y)\n",
    "                    \n",
    "                    # Ensure width and height are non-negative. COCO bboxes require w,h >= 0.\n",
    "                    bbox_w = max(0.0, max_x_s - min_x_s)\n",
    "                    bbox_h = max(0.0, max_y_s - min_y_s)\n",
    "                    bbox_coco_scaled = [min_x_s, min_y_s, bbox_w, bbox_h]\n",
    "\n",
    "                    # --- Area Calculation ---\n",
    "                    pixel_area_on_map_sq = 0.0\n",
    "                    # Ensure raster_transform components are valid numbers\n",
    "                    if (isinstance(raster_transform.a, (int, float)) and raster_transform.a == raster_transform.a and # not NaN\n",
    "                        isinstance(raster_transform.e, (int, float)) and raster_transform.e == raster_transform.e):   # not NaN\n",
    "                        pixel_area_on_map_sq = abs(raster_transform.a * raster_transform.e)\n",
    "                        if pixel_area_on_map_sq < 1e-12: # Treat extremely small values as zero\n",
    "                            print(f\"     WARNING: pixel_area_on_map_sq is near zero ({pixel_area_on_map_sq}) for {tif_filename}. Raster transform a={raster_transform.a}, e={raster_transform.e}.\")\n",
    "                            pixel_area_on_map_sq = 0.0\n",
    "                    else:\n",
    "                        print(f\"     WARNING: Invalid raster_transform elements (a={raster_transform.a}, e={raster_transform.e}) for {tif_filename}. Area calculation will be 0.\")\n",
    "                    \n",
    "                    original_pixel_area = 0.0\n",
    "                    if pixel_area_on_map_sq > 1e-9: # Avoid division by zero\n",
    "                        original_pixel_area = map_unit_area / pixel_area_on_map_sq\n",
    "                    elif map_unit_area > 1e-9 : # If map_unit_area is not zero but pixel_area_on_map_sq is\n",
    "                            print(f\"     WARNING: map_unit_area ({map_unit_area}) > 0 but pixel_area_on_map_sq is 0 for ann ID {current_annotation_id} in {tif_filename}. Setting pixel area to 0.\")\n",
    "                    # If both are 0, original_pixel_area remains 0, which is fine.\n",
    "\n",
    "                    scaled_pixel_area = original_pixel_area * (scale_factor ** 2)\n",
    "                    scaled_pixel_area = max(0.0, scaled_pixel_area) # Ensure non-negative\n",
    "\n",
    "                    # Final check for NaN/Inf in critical fields\n",
    "                    if any(coord != coord for coord in bbox_coco_scaled) or \\\n",
    "                        scaled_pixel_area != scaled_pixel_area: # Checks for NaN\n",
    "                        print(f\"   ERROR: NaN detected in bbox or area for ann ID {current_annotation_id} in {tif_filename} before appending.\")\n",
    "                        print(f\"     bbox: {bbox_coco_scaled}, area: {scaled_pixel_area}\")\n",
    "                        # Decrement counter and skip this problematic annotation\n",
    "                        global_annotation_id_counter -= 1 # Revert increment\n",
    "                        continue\n",
    "\n",
    "                    print(f\"DEBUG: Adding annotation ID {current_annotation_id} for Image ID {current_image_id}:\")\n",
    "                    print(f\"DEBUG:   Bbox: {bbox_coco_scaled}\")\n",
    "                    print(f\"DEBUG:   Area: {scaled_pixel_area}\")\n",
    "                    print(f\"DEBUG:   Number of segmentation parts: {len(coco_segments_for_ann)}\")\n",
    "\n",
    "                    coco_data[\"annotations\"].append({\n",
    "                        \"id\": current_annotation_id, # Use the stored current_annotation_id\n",
    "                        \"image_id\": current_image_id,\n",
    "                        \"category_id\": main_category_id,\n",
    "                        \"segmentation\": coco_segments_for_ann,\n",
    "                        \"area\": scaled_pixel_area, # MUST be a valid float/int\n",
    "                        \"bbox\": bbox_coco_scaled,   # MUST be a list of 4 valid floats/ints\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "            else: \n",
    "                print(f\"    No specific polygons from shapefile for {tif_filename} (this is expected if pre-filtering removed them or reprojection failed).\")\n",
    "\n",
    "            # Add the default \"unlabelled\" polygon for this image\n",
    "            global_annotation_id_counter += 1\n",
    "            unlabelled_segmentation = [[\n",
    "                0.0, 0.0, \n",
    "                float(scaled_img_width), 0.0,\n",
    "                float(scaled_img_width), float(scaled_img_height),\n",
    "                0.0, float(scaled_img_height)\n",
    "            ]]\n",
    "            unlabelled_bbox = [0.0, 0.0, float(scaled_img_width), float(scaled_img_height)]\n",
    "            unlabelled_area = float(scaled_img_width * scaled_img_height)\n",
    "\n",
    "            coco_data[\"annotations\"].append({\n",
    "                \"id\": global_annotation_id_counter, \"image_id\": current_image_id,\n",
    "                \"category_id\": unlabelled_category_id, \n",
    "                \"segmentation\": unlabelled_segmentation,\n",
    "                \"area\": unlabelled_area,\n",
    "                \"bbox\": unlabelled_bbox,\n",
    "                \"iscrowd\": 0 \n",
    "            })\n",
    "            print(f\"    Added default 'unlabelled' annotation for {tif_filename}.\")\n",
    "\n",
    "            pil_img_original = Image.open(tif_full_path)\n",
    "            print(f\"DEBUG: For {tif_filename} - Pillow opened original dimensions: {pil_img_original.width}x{pil_img_original.height}\")\n",
    "            destination_image_path = os.path.join(images_output_dir, tif_filename)\n",
    "\n",
    "            if abs(scale_factor - 1.0) < 1e-9:\n",
    "                print(f\"DEBUG: For {tif_filename} - Copying image, no scaling. Path: {destination_image_path}\")\n",
    "                shutil.copy2(tif_full_path, destination_image_path)\n",
    "            else:\n",
    "                print(f\"DEBUG: For {tif_filename} - Entering scaling block. Target: {scaled_img_width}x{scaled_img_height}. Resampling: {resampling_method}\")\n",
    "                scaled_img_pil = pil_img_original.resize((scaled_img_width, scaled_img_height), resampling_method)\n",
    "                print(f\"DEBUG: For {tif_filename} - Pillow resized dimensions (before save): {scaled_img_pil.width}x{scaled_img_pil.height}\")\n",
    "                try:\n",
    "                    print(f\"DEBUG: For {tif_filename} - Attempting to save SCALED image WITHOUT tiffinfo to {destination_image_path}\")\n",
    "                    scaled_img_pil.save(destination_image_path)\n",
    "                    print(f\"DEBUG: For {tif_filename} - Successfully saved SCALED image WITHOUT tiffinfo to {destination_image_path}\")\n",
    "                except Exception as save_e:\n",
    "                    print(f\"    ERROR: Could not save {tif_filename} even without TIFF tags after scaling: {save_e}.\")\n",
    "            pil_img_original.close()\n",
    "\n",
    "        except rasterio.errors.RasterioIOError as rio_e:\n",
    "            print(f\"    ERROR: Rasterio could not open or read {tif_filename} in main processing: {rio_e}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"    ERROR: File not found for Pillow processing (was it moved/deleted after pre-filter?): {tif_full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR processing file {tif_filename}: {e.__class__.__name__} - {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    output_json_filename = os.path.join(annotations_output_dir, \"instances.json\")\n",
    "    with open(output_json_filename, 'w') as f: json.dump(coco_data, f, indent=4)\n",
    "    print(f\"  Saved all annotations to {output_json_filename}\")\n",
    "\n",
    "    parent_dir_of_output = os.path.dirname(output_directory_path.rstrip(os.sep))\n",
    "    if not parent_dir_of_output:\n",
    "        parent_dir_of_output = \".\"\n",
    "    archive_base_name = os.path.join(parent_dir_of_output, os.path.basename(output_directory_path.rstrip(os.sep)) + \"_coco_dataset\")\n",
    "\n",
    "    print(f\"\\nCreating ZIP archive from contents of: {output_directory_path}\")\n",
    "    print(f\"Archive will be saved as: {archive_base_name}.zip\")\n",
    "\n",
    "    try:\n",
    "        zip_output_path = shutil.make_archive(\n",
    "            base_name=archive_base_name,\n",
    "            format='zip',\n",
    "            root_dir=output_directory_path\n",
    "        )\n",
    "        print(f\"Successfully created ZIP archive: {zip_output_path}\")\n",
    "        return zip_output_path\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR creating ZIP archive: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        print(f\"COCO dataset creation finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # --- USER CONFIGURATION ---\n",
    "    input_tifs_folder = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2021_08_19_lac_murray\\TIFFs\"  # MODIFY THIS\n",
    "    input_polygon_shp = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2021_08_19_lac_murray\\Lac_Murray ArcGIS\\Polygons_Merge.shp\"\n",
    "    output_coco_dir = r\"C:\\Users\\kevin\\dev\\tornado-tree-destruction-ef\\tornado-tree-destruction-ef\\data\\2021_08_19_lac_murray\\coco\"  # MODIFY THIS\n",
    "\n",
    "\n",
    "    # Optional: Provide a list of specific TIF filenames to include.\n",
    "    # If None, all TIFs in input_tifs_folder will be considered.\n",
    "    # Example: specific_tifs_to_include = [\"image1.tif\", \"image3.tif\"]\n",
    "    specific_tifs_to_include: Optional[List[str]] = [\"2019_Lac Murray_597700_5262700.tif\", \"2019_Lac Murray_599700_5261200.tif\", \"2019_Lac Murray_598700_5262200.tif\", \"2019_Lac Murray_599200_5262200.tif\", \"2019_Lac Murray_599700_5262200.tif\", \"2019_Lac Murray_606200_5264200.tif\"]\n",
    "    # specific_tifs_to_include = [\"dummy_image_1.tif\"] # Example for dummy data test\n",
    "\n",
    "    image_annotation_scale_factor = 1.0  # Example: 0.5 to halve dimensions, 1.0 for no change.\n",
    "\n",
    "    category = \"fallen\"\n",
    "    super_category = \"super\"\n",
    "    description = \"Custom COCO dataset with specific objects and unlabelled background.\"\n",
    "    contributor = \"Your Name/Organization\"\n",
    "    license_nm = \"Your License Name (e.g., CC BY 4.0)\"\n",
    "    license_link = \"Link to your license (e.g., https://creativecommons.org/licenses/by/4.0/)\"\n",
    "    # --- END USER CONFIGURATION ---\n",
    "\n",
    "    current_resampling_method = Image.Resampling.LANCZOS\n",
    "\n",
    "    try:\n",
    "        generated_zip_file = create_coco_dataset_no_arcpy(\n",
    "            tif_folder_path=input_tifs_folder,\n",
    "            polygon_shapefile_path=input_polygon_shp,\n",
    "            output_directory_path=output_coco_dir,\n",
    "            include_tifs_list=specific_tifs_to_include, # Pass the list here\n",
    "            scale_factor=image_annotation_scale_factor,\n",
    "            coco_category_name=category,\n",
    "            coco_supercategory_name=super_category,\n",
    "            dataset_description=description,\n",
    "            contributor_name=contributor,\n",
    "            coco_license_name=license_nm,\n",
    "            coco_license_url=license_link,\n",
    "            resampling_method=current_resampling_method\n",
    "        )\n",
    "\n",
    "        if generated_zip_file:\n",
    "            print(f\"\\n--- SCRIPT FINISHED SUCCESSFULLY ---\")\n",
    "            print(f\"COCO dataset ZIP archive created at: {generated_zip_file}\")\n",
    "            print(f\"Intermediate COCO structure (before zipping) is at: {output_coco_dir}\")\n",
    "        else:\n",
    "            print(f\"\\n--- SCRIPT FINISHED WITH ERRORS OR NO VALID IMAGES ---\")\n",
    "            print(f\"COCO dataset generation may have failed or no images met the criteria. Please review the logs.\")\n",
    "            print(f\"Intermediate COCO structure (if any) is at: {output_coco_dir}\")\n",
    "\n",
    "    except ImportError as ie:\n",
    "        print(f\"An import error occurred: {ie}\")\n",
    "        print(\"Please ensure you have installed all required libraries:\")\n",
    "        print(\"pip install rasterio geopandas shapely Pillow pyproj\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in the main execution block: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603994c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-checked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
